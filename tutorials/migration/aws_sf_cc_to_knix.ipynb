{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright 2020 The KNIX Authors\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Migrating workflow from AWS Stepfunctions to KNIX\n",
    "\n",
    "KNIX is compatible with AWS Lambda and Step Functions with expanded support for sophisticated parallel executions. This tutorial shows how to migrate an existing AWS StepFunctions workflow from an AWS tutorial to KNIX:\n",
    "\n",
    "https://aws.amazon.com/de/getting-started/hands-on/create-a-serverless-workflow-step-functions-lambda/\n",
    "\n",
    "## Goal for this Notebook:\n",
    "Show a simple example of migrating sample workflows in Python, using SDKs provided for both AWS and KNIX. This is aimed for those looking to get into the field or those who are already in the field and looking to see an example how to move existing workflows between AWS and KNIX.\n",
    "\n",
    "### This Notebook will show basic examples of:\n",
    "* Importing SDKs\n",
    "* Generating and using SDK objects\n",
    "* Converting ARNs to KNIX names \n",
    "* Convert AWS Lambda deployment packages\n",
    "* Import and export worflow and function definitions\n",
    "\n",
    "### Required Libraries:\n",
    "* [json] (http://www.json.org/)\n",
    "* [zipfile] (https://docs.python.org/3/library/zipfile)\n",
    "\n",
    "### Things to remember:\n",
    "\n",
    "* In Step-Functions workflow descriptions, 'Resource' ARN needs to be changed into real Lambda ARNs. This can be achieved by prepending a fixed, user-specific prefix of the form of \"arn:aws:lambda:eu-central-1:123456789012:function:\" . Note this step does not require any change in user code.\n",
    "\n",
    "* In Lambda,  function handler needs to be configured when creating the function. In KNIX the function handler name must always be called \"handle\". Note this step does not require changing user code.\n",
    "\n",
    "* KNIX users should put the libraries that they would like to be part of LD_LIBRARY_PATH in a ./lib/ folder, which is inside their deployment zip and sits parallel to their fuction code (referring to the .py file that has the 'handle' method)\n",
    "\n",
    "* In KNIX, if user's deployment zip contains ELF executable binaries that can be invoked from the python code (using the subprocess module), then these binaries should be invoked using their complete path, and not via symbolic links to them.\n",
    "\n",
    "* User code in Lambda is only allowed to create files in /tmp, whereas, in KNIX the entire filesystem is writable.\n",
    "\n",
    "\n",
    "## Now let's start to migrate a workflow from KNIX to AWS. \n",
    "\n",
    "First, install the required AWS SDK. Please note that you need to configure your credentials for using this SDK, e.g by adding your credentials to ~/.aws/config:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Using cached https://files.pythonhosted.org/packages/1d/3e/95edad6297483d8d4985486f54c8c5441bdd5f0726918dbfe26cd32bc6a4/boto3-1.14.3-py2.py3-none-any.whl\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting botocore<1.18.0,>=1.17.3 (from boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/b7/15/fb65d9dc6194dc9f1a9cd5f4c64c884288919562fe84159641d6154318f4/botocore-1.17.3-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.26,>=1.20; python_version != \"3.4\" (from botocore<1.18.0,>=1.17.3->boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl\n",
      "Collecting docutils<0.16,>=0.10 (from botocore<1.18.0,>=1.17.3->boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore<1.18.0,>=1.17.3->boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting six>=1.5 (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.3->boto3)\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Installing collected packages: jmespath, urllib3, docutils, six, python-dateutil, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.14.3 botocore-1.17.3 docutils-0.16 jmespath-0.10.0 python-dateutil-2.8.1 s3transfer-0.3.3 six-1.15.0 urllib3-1.25.9\n"
     ]
    }
   ],
   "source": [
    "!pip3 install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import the required librares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "from mfn_sdk import MfnClient\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get a boto3 client object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_sf = boto3.client('stepfunctions')\n",
    "client_lambda = boto3.client('lambda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your credentials to get a knix client object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_mfn = MfnClient(\n",
    "    #mfn_url=\"http://knix.io/mfn\",\n",
    "    mfn_url=\"http://localhost:8080\",\n",
    "    mfn_user=\"mfn@mfn\",\n",
    "    mfn_password=\"mfn\",\n",
    "    mfn_name=\"KS\",\n",
    "    proxies={\"http_proxy\": \"None\", \"https_proxy\": \"None\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a few parameters to prepare the data access to AWS services suchas as Lambda and Stepfunctions:\n",
    "* lambdaprefix: the ARN name prefix for AWS Lambda functions\n",
    "* awsSfRoleName: the name (ARN) allowing the boto3 client to access the the AWS Stepfunctions service\n",
    "* knixWfName: the name of the source workflow on KNIX\n",
    "* sfWFName: the name of the target workflow on AWS Stepfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to get the correct AWS state machine arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_machine_arn(name):\n",
    "        \"\"\"\n",
    "        Get a state machine given its name\n",
    "        \"\"\"\n",
    "        response = client_sf.list_state_machines()\n",
    "        if not response.get('stateMachines'):\n",
    "            return None\n",
    "        for sm in response.get('stateMachines'):\n",
    "            if sm['name'] == name:\n",
    "                return sm['stateMachineArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to convert lambda deployment package and upload to KNIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lambda_and_upload_as_mfn(local, lambda_arn):\n",
    "    \"\"\"\n",
    "    Convert lambdas into mfn deployment packages and upload them \n",
    "    \"\"\"    \n",
    "    response = client_lambda.get_function(FunctionName=lambda_arn)    \n",
    "        \n",
    "    awsfile = lambda_arn.split(\":\")[-1]\n",
    "    print (\"awsfile: \" + awsfile)\n",
    "    awshandler = str(response['Configuration']['Handler'].split(\".\")[1])\n",
    "    #print (\"awshandler:\" +  awshandler)\n",
    "    \n",
    "    if \"S3\" in json.dumps(response['Code']['RepositoryType']): # we need to handle a deployment package\n",
    "        url =  str(response['Code']['Location'])\n",
    "        filein = urllib.request.urlretrieve(url)[0]  # download the Lambda deployment package from AWS\n",
    "        print (\"Lambda Function deployment package:  \",  filein)\n",
    "\n",
    "        with ZipFile(filein, 'r') as zip_ref: # extract lambda_file to local dir\n",
    "            zip_ref.extractall(local)\n",
    "            \n",
    "        fin = open(local +  \"lambda_function.py\", \"rt\") # open extracted file\n",
    "        fout = open(local + awsfile+\".py\", \"wt\") # open new python file for modified source code (handler)\n",
    "        mfnhandler = \"handle\" # Mfn grain handle needs to be \"handle\"\n",
    "\n",
    "        for line in fin:\n",
    "            # replace the lambda handler and write to new python source file compatible with knix\n",
    "            fout.write(line.replace(awshandler, mfnhandler))\n",
    "            \n",
    "        fin.close() # close input file\n",
    "        os.remove(local + \"lambda_function.py\") # cleanup lambda function file \n",
    "        fout.close() # close output file\n",
    "        \n",
    "        with ZipFile(local +  awsfile+\".zip\", 'w') as zip_ref: # generate new deployment file compatibl with knix\n",
    "            zip_ref.write(local + awsfile+\".py\")        \n",
    "                        \n",
    "        mfn = client_mfn.add_function(awsfile) # add function to mfn\n",
    "\n",
    "        zip_name = local + \"%s.zip\" % (awsfile) # get deployment package file name\n",
    "\n",
    "        mfn.upload(zip_name) # upload deployment package to KNIX\n",
    "        \n",
    "    else: # no deployment package for this lambda\n",
    "        raise Exception(\"Error: Non-supported lambda repository type\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set the the AWS Step Functions source state machine name and target KNIX workflow name for migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = str(boto3.resource('iam').CurrentUser().arn.split(\":\")[4])\n",
    "sm_name = \"CallCenterStateMachine\" # name of the source State Machine\n",
    "sm_arn = \"arn:aws:states:eu-central-1:%s:stateMachine:%s\" % (user_id, sm_name)\n",
    "knix_wf_name = \"test_wf_knix\" # target state machine name on KNIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the conversion loop over all States Machine states "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CallCenterStateMachine ... \n",
      "processing AssignCaseFunction\n",
      "awsfile: AssignCaseFunction\n",
      "Lambda Function deployment package:   /tmp/tmpz6smv3eu\n",
      "Uploading function zip: AssignCaseFunction\n",
      "100.0 % \n",
      "processing CloseCaseFunction\n",
      "awsfile: CloseCaseFunction\n",
      "Lambda Function deployment package:   /tmp/tmp1_i3jfek\n",
      "Uploading function zip: CloseCaseFunction\n",
      "100.0 % \n",
      "processing EscalateCaseFunction\n",
      "awsfile: EscalateCaseFunction\n",
      "Lambda Function deployment package:   /tmp/tmps7upb9to\n",
      "Uploading function zip: EscalateCaseFunction\n",
      "100.0 % \n",
      "processing Fail\n",
      "Info: Non-Task State, not converted!\n",
      "processing IsCaseResolved\n",
      "Info: Non-Task State, not converted!\n",
      "processing OpenCaseFunction\n",
      "awsfile: OpenCaseFunction\n",
      "Lambda Function deployment package:   /tmp/tmphfzepnn8\n",
      "Uploading function zip: OpenCaseFunction\n",
      "100.0 % \n",
      "processing WorkOnCaseFunction\n",
      "awsfile: WorkOnCaseFunction\n",
      "Lambda Function deployment package:   /tmp/tmpoh4guipy\n",
      "Uploading function zip: WorkOnCaseFunction\n",
      "100.0 % \n",
      "Uploading modified workflow to KNIX: test_wf_knix\n",
      "Workflow and grains successfully uploaded to KNIX!\n"
     ]
    }
   ],
   "source": [
    "local = \"./deployment_packages/\" #\"C:\\\\Python36\\\\Scripts\\\\\"\n",
    "    \n",
    "try:\n",
    "    if not os.path.exists(os.path.dirname(local)):\n",
    "        os.makedirs(os.path.dirname(local))\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "\n",
    "\n",
    "# query state machine at AWS SF\n",
    "response = client_sf.describe_state_machine(stateMachineArn=sm_arn)\n",
    "#print(\"Response: \" + str(response))\n",
    "\n",
    "print (\"Processing %s ... \" % response['name'])\n",
    "awssfwf = json.loads(response['definition'])\n",
    "\n",
    "for att, val in awssfwf['States'].items(): # loop over all states with Resources    \n",
    "    print (\"processing %s\" % (att))\n",
    "    if \"Resource\" in val.keys():        \n",
    "        #response_l = client_lambda.get_function(FunctionName=val['Resource'])\n",
    "        convert_lambda_and_upload_as_mfn(local, val['Resource'])\n",
    "        val['Resource'] =  val['Resource'].split(\":\")[-1] # remove arn prefix        \n",
    "    else:\n",
    "        print(\"Info: Non-Task State, not converted!\")\n",
    "        pass\n",
    "            \n",
    "print (\"Uploading modified workflow to KNIX: %s\" % knix_wf_name)\n",
    "\n",
    "test_wf_knix = client_mfn.add_workflow(knix_wf_name)\n",
    "test_wf_knix.json = json.dumps(awssfwf, indent=2, sort_keys=True)\n",
    "\n",
    "print (\"Workflow and grains successfully uploaded to KNIX!\")\n",
    "\n",
    "# finally, let's clean up local directories\n",
    "shutil.rmtree(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting workflow deployment...\n",
      "Workflow deployed, sending input...\n",
      "Received result: {'Case': '001', 'Status': 0, 'Message': 'Case 001: opened...assigned...unresolved...escalating.'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting workflow deployment...\")\n",
    "test_wf_knix.deploy(timeout=0)\n",
    "print(f\"Workflow deployed, sending input...\")\n",
    "result = test_wf_knix.execute({\"inputCaseID\": \"001\"})\n",
    "\"\"\"\n",
    "Success: \n",
    "{\n",
    "  \"output\": {\n",
    "    \"Case\": \"001\",\n",
    "    \"Status\": 1,\n",
    "    \"Message\": \"Case 001: opened...assigned...closed.\"\n",
    "  },\n",
    "  \"outputDetails\": null\n",
    "}\n",
    "or\n",
    "{\n",
    "  \"output\": {\n",
    "    \"Case\": \"001\",\n",
    "    \"Status\": 0,\n",
    "    \"Message\": 'Message': 'Case 001: opened...assigned...unresolved...escalating.'}\n",
    "  },\n",
    "  \"outputDetails\": null\n",
    "}\n",
    "Fail:\n",
    "{\n",
    "  \"error\": null,\n",
    "  \"cause\": \"Engage Tier 2 Support.\"\n",
    "}\n",
    "\"\"\"\n",
    "print(f\"Received result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have migrated successfully a workflow from AWS Stepfunctions to KNIX!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](knix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
